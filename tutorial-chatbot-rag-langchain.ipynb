{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install -q langchain langchain-community langchain_huggingface chromadb wikipedia","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T09:07:48.298715Z","iopub.execute_input":"2024-11-05T09:07:48.299139Z","iopub.status.idle":"2024-11-05T09:08:34.655162Z","shell.execute_reply.started":"2024-11-05T09:07:48.299101Z","shell.execute_reply":"2024-11-05T09:08:34.653886Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom langchain_community.document_loaders import WikipediaLoader\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\nfrom langchain_community.vectorstores import Chroma\nfrom langchain.chains import RetrievalQA\nfrom langchain.prompts import PromptTemplate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T09:08:55.977798Z","iopub.execute_input":"2024-11-05T09:08:55.978255Z","iopub.status.idle":"2024-11-05T09:08:57.507896Z","shell.execute_reply.started":"2024-11-05T09:08:55.978211Z","shell.execute_reply":"2024-11-05T09:08:57.506449Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"YOUR-API-TOKEN\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T09:08:57.510633Z","iopub.execute_input":"2024-11-05T09:08:57.511359Z","iopub.status.idle":"2024-11-05T09:08:57.517774Z","shell.execute_reply.started":"2024-11-05T09:08:57.511284Z","shell.execute_reply":"2024-11-05T09:08:57.515660Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.environ.get(\"HUGGINGFACEHUB_API_TOKEN\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T09:08:59.118890Z","iopub.execute_input":"2024-11-05T09:08:59.119288Z","iopub.status.idle":"2024-11-05T09:08:59.128442Z","shell.execute_reply.started":"2024-11-05T09:08:59.119252Z","shell.execute_reply":"2024-11-05T09:08:59.127239Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.llms import HuggingFaceHub\n\n# set Korean embedding and llm odel\nhf_embeddings = HuggingFaceEmbeddings(model_name=\"jhgan/ko-sroberta-multitask\")\n\nhf_llm = HuggingFaceHub(\n    repo_id=\"skt/kogpt2-base-v2\",\n    model_kwargs={\"task\": \"text-generation\"} ## question-answering tasK X. text-generation\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T09:09:00.358951Z","iopub.execute_input":"2024-11-05T09:09:00.359326Z","iopub.status.idle":"2024-11-05T09:09:27.632935Z","shell.execute_reply.started":"2024-11-05T09:09:00.359292Z","shell.execute_reply":"2024-11-05T09:09:27.631871Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import requests\nfrom langchain.schema import Document\nfrom bs4 import BeautifulSoup\n\n# By default, English documents (https://en.wikipedia.org))\n# def load_Wiki_docs(\"í‘ë°±ìš”ë¦¬ì‚¬\"):\n#     loader = WikipediaLoader(query=query, load_max_docs=1)\n#     documents = loader.load()\n    \n#     text_splitter = RecursiveCharacterTextSplitter(\n#         chunk_size=1000,\n#         chunk_overlap=200\n#     )\n#     splits = text_splitter.split_documents(documents)\n    \n#     return splits\n\n\n# For Korean query, get results from Korean wikipedia website and crawl and parse results\ndef load_Korean_wiki_docs(topic):\n\n    url = f\"https://ko.wikipedia.org/wiki/{topic}\"\n    \n    response = requests.get(url)\n    response.raise_for_status()  # raise Exception when error occurs\n\n    # HTML parsing and extract body contents\n    soup = BeautifulSoup(response.text, 'html.parser')\n    content = soup.find('div', {'class': 'mw-parser-output'})  # find div including body contents \n    \n    # Extract contents\n    paragraphs = content.find_all('p')\n    text = \"\\n\".join([p.get_text() for p in paragraphs])  # concat all context in <p> tags \n \n    # convert to Document object (required for LangChain)\n    documents = [Document(page_content=text, metadata={\"source\": url})]\n    \n    text_splitter = RecursiveCharacterTextSplitter(\n        chunk_size=1000,\n        chunk_overlap=200\n    )\n    splits = text_splitter.split_documents(documents)\n    \n    return splits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T09:09:27.634778Z","iopub.execute_input":"2024-11-05T09:09:27.635488Z","iopub.status.idle":"2024-11-05T09:09:27.821675Z","shell.execute_reply.started":"2024-11-05T09:09:27.635443Z","shell.execute_reply":"2024-11-05T09:09:27.820531Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_vectorstore(splits): \n    vectorstore = Chroma.from_documents(documents=splits, embedding=hf_embeddings)\n    return vectorstore","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T09:09:27.823113Z","iopub.execute_input":"2024-11-05T09:09:27.824332Z","iopub.status.idle":"2024-11-05T09:09:27.829796Z","shell.execute_reply.started":"2024-11-05T09:09:27.824262Z","shell.execute_reply":"2024-11-05T09:09:27.828673Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"topic = \"í‘ë°±ìš”ë¦¬ì‚¬\"\n# Load wikipedia documents for this topic\nsplits = load_Korean_wiki_docs(topic)\n# Create vectorstore with this fetched docs\nvectorstore = create_vectorstore(splits)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T09:09:27.832555Z","iopub.execute_input":"2024-11-05T09:09:27.833303Z","iopub.status.idle":"2024-11-05T09:09:29.373257Z","shell.execute_reply.started":"2024-11-05T09:09:27.833250Z","shell.execute_reply":"2024-11-05T09:09:29.372176Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"splits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T09:09:29.374508Z","iopub.execute_input":"2024-11-05T09:09:29.374856Z","iopub.status.idle":"2024-11-05T09:09:29.381593Z","shell.execute_reply.started":"2024-11-05T09:09:29.374819Z","shell.execute_reply":"2024-11-05T09:09:29.380291Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 1. Use langchain RAG","metadata":{}},{"cell_type":"code","source":"def create_rag_chain(vectorstore):\n    prompt_template = \"\"\"ë¬¸ë§¥ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ë‹µí•˜ì‹­ì‹œì˜¤.\n    ë¬¸ë§¥: {context}\n    ì§ˆë¬¸: {question}\n    ë‹µë³€:\"\"\"\n    PROMPT = PromptTemplate(\n        template=prompt_template, input_variables=[\"context\", \"question\"]\n    )\n\n    chain_type_kwargs = {\"prompt\": PROMPT}\n\n    # Make context shorter\n    # def short_context(context, max_length=300):\n    #     return context[:max_length] if len(context) > max_length else context\n    \n    # class ShortContextRetriever(BaseRetriever):\n    #     def __init__(self, retriever):\n    #         super().__init__()\n    #         self._retriever = retriever\n        \n    #     def get_relevant_documents(self, query):\n    #         docs = self._retriever.get_relevant_documents(query)\n    #         for doc in docs:\n    #             doc.page_content = short_context(doc.page_content)\n    #         return docs\n    \n    # retriever = ShortContextRetriever(vectorstore.as_retriever())\n    \n    qa_chain = RetrievalQA.from_chain_type(\n        llm=hf_llm,\n        chain_type=\"stuff\",\n        retriever=vectorstore.as_retriever(),\n        chain_type_kwargs=chain_type_kwargs,\n        return_source_documents=True\n    )\n    \n    return qa_chain","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T09:09:29.383298Z","iopub.execute_input":"2024-11-05T09:09:29.383780Z","iopub.status.idle":"2024-11-05T09:09:29.396488Z","shell.execute_reply.started":"2024-11-05T09:09:29.383730Z","shell.execute_reply":"2024-11-05T09:09:29.395399Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# create langchang RAG chain\nqa_chain = create_rag_chain(vectorstore)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T09:09:29.397826Z","iopub.execute_input":"2024-11-05T09:09:29.398256Z","iopub.status.idle":"2024-11-05T09:09:29.415242Z","shell.execute_reply.started":"2024-11-05T09:09:29.398206Z","shell.execute_reply":"2024-11-05T09:09:29.413906Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"question = \"ì‹¬ì‚¬ìœ„ì›ì„ ëˆ„ê°€ ë§¡ì•˜ì–´?\"\n\n# result = qa_chain({\"query\": question})\nresult = qa_chain.invoke({\"query\": question})\n\nprint (\"ê²°ê³¼:\")\nprint(result[\"result\"])\n\nprint(\"ì¶œì²˜:\")\nfor doc in result[\"source_documents\"]:\n    print(doc.page_content)\n    print(\"---\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T09:12:01.544448Z","iopub.execute_input":"2024-11-05T09:12:01.544883Z","iopub.status.idle":"2024-11-05T09:12:02.047841Z","shell.execute_reply.started":"2024-11-05T09:12:01.544843Z","shell.execute_reply":"2024-11-05T09:12:02.045748Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"docs = vectorstore.as_retriever().get_relevant_documents(question)\ndocs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T09:10:05.112289Z","iopub.execute_input":"2024-11-05T09:10:05.112736Z","iopub.status.idle":"2024-11-05T09:10:05.184005Z","shell.execute_reply.started":"2024-11-05T09:10:05.112696Z","shell.execute_reply":"2024-11-05T09:10:05.182736Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"docs = vectorstore.similarity_search(question, k=4)\ndocs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T09:09:53.380512Z","iopub.execute_input":"2024-11-05T09:09:53.380938Z","iopub.status.idle":"2024-11-05T09:09:53.455173Z","shell.execute_reply.started":"2024-11-05T09:09:53.380897Z","shell.execute_reply":"2024-11-05T09:09:53.453947Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2. Use QA pipeline with vectorstor similarity search","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n\n# Load model and tokenizer\nmodel_name = \"yjgwak/klue-bert-base-finetuned-squard-kor-v1\"\nmodel = AutoModelForQuestionAnswering.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\n# Set Q_A pipeline\nqa_pipeline = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T09:09:55.379646Z","iopub.execute_input":"2024-11-05T09:09:55.380074Z","iopub.status.idle":"2024-11-05T09:09:59.512847Z","shell.execute_reply.started":"2024-11-05T09:09:55.380025Z","shell.execute_reply":"2024-11-05T09:09:59.511655Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Example: define question and context \nquestion = \"ì˜¤ëŠ˜ ë‚ ì”¨ ì–´ë•Œ?\"\ncontext = \"ì˜¤ëŠ˜ì˜ ë‚ ì”¨ëŠ” ë§‘ê³  ë”°ëœ»í•œ ê¸°ì˜¨ì´ ìœ ì§€ë  ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.\"\n\n# model chain\nresult = qa_pipeline(question=question, context=context)\n\n# Result\nprint(\"ì§ˆë¬¸:\", question)\nprint(\"ë‹µë³€:\", result['answer'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T09:09:59.515027Z","iopub.execute_input":"2024-11-05T09:09:59.515429Z","iopub.status.idle":"2024-11-05T09:09:59.629456Z","shell.execute_reply.started":"2024-11-05T09:09:59.515388Z","shell.execute_reply":"2024-11-05T09:09:59.628369Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# search context in VectorStore\ndef retrieve_context(question, vectorstore):\n    docs = vectorstore.similarity_search(question, k=1)\n    if docs:\n        return docs[0].page_content  # return first relevant doc\n    else:\n        return None\n\n# Generate answer based on query and searched context similar to RAG chain\ndef answer_question_with_context(question, vectorstore):\n    context = retrieve_context(question, vectorstore)\n    if context:\n        result = qa_pipeline(question=question, context=context)\n        return result['answer'], context  # return answer and used source doc\n    else:\n        return \"ê´€ë ¨ ë¬¸ë§¥ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\", None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T09:09:59.631219Z","iopub.execute_input":"2024-11-05T09:09:59.631692Z","iopub.status.idle":"2024-11-05T09:09:59.639201Z","shell.execute_reply.started":"2024-11-05T09:09:59.631637Z","shell.execute_reply":"2024-11-05T09:09:59.637878Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Example\nquestion = \"ì‹¬ì‚¬ìœ„ì›ì„ ëˆ„ê°€ ë§¡ì•˜ì–´?\"\n\nanswer, used_context = answer_question_with_context(question, vectorstore)\n\nprint(\"ì§ˆë¬¸:\", question)\nprint(\"ë‹µë³€:\", answer)\nprint(\"ì‚¬ìš©ëœ ë¬¸ë§¥:\", used_context)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T09:09:59.641564Z","iopub.execute_input":"2024-11-05T09:09:59.642022Z","iopub.status.idle":"2024-11-05T09:09:59.907611Z","shell.execute_reply.started":"2024-11-05T09:09:59.641984Z","shell.execute_reply":"2024-11-05T09:09:59.906432Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. Use Gemini+RAG","metadata":{}},{"cell_type":"code","source":"pip install -q langchain langchain-community langchain_huggingface chromadb google-generativeai","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T07:24:31.685998Z","iopub.execute_input":"2024-11-06T07:24:31.686993Z","iopub.status.idle":"2024-11-06T07:24:45.509156Z","shell.execute_reply.started":"2024-11-06T07:24:31.686928Z","shell.execute_reply":"2024-11-06T07:24:45.507604Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"from langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.vectorstores import Chroma\nfrom langchain.schema import Document\nfrom langchain.llms import OpenAI\nimport google.generativeai as genai\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T07:24:45.511349Z","iopub.execute_input":"2024-11-06T07:24:45.511833Z","iopub.status.idle":"2024-11-06T07:24:45.519835Z","shell.execute_reply.started":"2024-11-06T07:24:45.511787Z","shell.execute_reply":"2024-11-06T07:24:45.518803Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\"\ngenai_api_key = \"AIzaSyCOwQooLC4TxzeIYeuICKJY2nTp4Y55QSA\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T07:24:51.323426Z","iopub.execute_input":"2024-11-06T07:24:51.324498Z","iopub.status.idle":"2024-11-06T07:24:51.328994Z","shell.execute_reply.started":"2024-11-06T07:24:51.324448Z","shell.execute_reply":"2024-11-06T07:24:51.327900Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"genai.configure(api_key=genai_api_key)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T07:24:51.995355Z","iopub.execute_input":"2024-11-06T07:24:51.995803Z","iopub.status.idle":"2024-11-06T07:24:52.001411Z","shell.execute_reply.started":"2024-11-06T07:24:51.995731Z","shell.execute_reply":"2024-11-06T07:24:52.000207Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# 1. Gemini model\ngemini_model = genai.GenerativeModel('gemini-1.5-flash')\n\n# 2. embedding model\nembedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\") ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T07:24:59.926056Z","iopub.execute_input":"2024-11-06T07:24:59.926485Z","iopub.status.idle":"2024-11-06T07:25:03.620946Z","shell.execute_reply.started":"2024-11-06T07:24:59.926449Z","shell.execute_reply":"2024-11-06T07:25:03.619640Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"from langchain.vectorstores import Chroma\n# sample docs\ndocs = [\n    Document(page_content=\"í•œêµ­ì–´ ì±—ë´‡ì€ ìì—°ì–´ ì²˜ë¦¬ ê¸°ìˆ ì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ìì™€ ëŒ€í™”ë¥¼ ë‚˜ëˆ•ë‹ˆë‹¤.\", metadata={\"source\": \"doc1\"}),\n    Document(page_content=\"ì¸ê³µì§€ëŠ¥ì„ í™œìš©í•œ ì±—ë´‡ì€ ì—¬ëŸ¬ ì‚°ì—…ì—ì„œ ì‚¬ìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤.\", metadata={\"source\": \"doc2\"}),\n    Document(page_content=\"í•œêµ­ì–´ì™€ ì˜ì–´ë¥¼ ë™ì‹œì— ì§€ì›í•˜ëŠ” ì±—ë´‡ì´ ì ì  ëŠ˜ì–´ë‚˜ê³  ìˆìŠµë‹ˆë‹¤.\", metadata={\"source\": \"doc3\"}),\n    Document(page_content=\"ì±—ë´‡ì€ ê³ ê° ì„œë¹„ìŠ¤ë¥¼ ê°œì„ í•˜ê³  ì‚¬ìš©ì ê²½í—˜ì„ í–¥ìƒì‹œí‚¤ëŠ” ë° ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.\", metadata={\"source\": \"doc4\"})\n]\n\n# to avoid collision with previous one\npersist_directory = \"./new_chroma_db\"\n\nvectorstore = Chroma.from_documents(docs, embedding=embedding_model, persist_directory=\"./chroma_db\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T07:25:07.523097Z","iopub.execute_input":"2024-11-06T07:25:07.523548Z","iopub.status.idle":"2024-11-06T07:25:07.621501Z","shell.execute_reply.started":"2024-11-06T07:25:07.523503Z","shell.execute_reply":"2024-11-06T07:25:07.620136Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# RAG using prompt\ndef rag_chatbot(question):\n    context_doc = vectorstore.similarity_search(question, k=1)\n    context = context_doc[0].page_content if context_doc else \"ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n\n    prompt = f\"Context: {context}\\nQuestion: {question}\\nAnswer in a complete sentence:\"\n    # response = gemini_model(prompt)\n    \n    response = gemini_model.generate_content(prompt)\n    answer = response.candidates[0].content.parts[0].text\n\n    print(\"ì¶œì²˜ ë¬¸ì„œ:\", context)\n    return answer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T07:25:08.546840Z","iopub.execute_input":"2024-11-06T07:25:08.547289Z","iopub.status.idle":"2024-11-06T07:25:08.554065Z","shell.execute_reply.started":"2024-11-06T07:25:08.547247Z","shell.execute_reply":"2024-11-06T07:25:08.552823Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# sample question\nquestion = \"ì±—ë´‡ì´ ì–´ë–¤ ê¸°ìˆ ì„ ì‚¬ìš©í•˜ë‚˜ìš”?\"\nresponse = rag_chatbot(question)\n\nprint(\"ì§ˆë¬¸:\", question)\nprint(\"ë‹µë³€:\", response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T07:25:09.387569Z","iopub.execute_input":"2024-11-06T07:25:09.388649Z","iopub.status.idle":"2024-11-06T07:25:10.829304Z","shell.execute_reply.started":"2024-11-06T07:25:09.388599Z","shell.execute_reply":"2024-11-06T07:25:10.828077Z"}},"outputs":[{"name":"stdout","text":"ì¶œì²˜ ë¬¸ì„œ: ì¸ê³µì§€ëŠ¥ì„ í™œìš©í•œ ì±—ë´‡ì€ ì—¬ëŸ¬ ì‚°ì—…ì—ì„œ ì‚¬ìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤.\nì§ˆë¬¸: ì±—ë´‡ì´ ì–´ë–¤ ê¸°ìˆ ì„ ì‚¬ìš©í•˜ë‚˜ìš”?\në‹µë³€: ì±—ë´‡ì€ ìì—°ì–´ ì²˜ë¦¬(NLP), ê¸°ê³„ í•™ìŠµ, ë”¥ ëŸ¬ë‹ê³¼ ê°™ì€ ê¸°ìˆ ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. \n\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"question = \"ì ì‹¬ë©”ë‰´ ì¶”ì²œí•´ì¤˜\"\nresponse = rag_chatbot(question)\n\nprint(\"ì§ˆë¬¸\" , question)\nprint(\"ë‹¨ë³€\" , response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T07:25:41.918306Z","iopub.execute_input":"2024-11-06T07:25:41.918768Z","iopub.status.idle":"2024-11-06T07:25:42.888362Z","shell.execute_reply.started":"2024-11-06T07:25:41.918709Z","shell.execute_reply":"2024-11-06T07:25:42.887152Z"}},"outputs":[{"name":"stdout","text":"ì¶œì²˜ ë¬¸ì„œ: í•œêµ­ì–´ ì±—ë´‡ì€ ìì—°ì–´ ì²˜ë¦¬ ê¸°ìˆ ì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ìì™€ ëŒ€í™”ë¥¼ ë‚˜ëˆ•ë‹ˆë‹¤.\nì§ˆë¬¸ ì ì‹¬ë©”ë‰´ ì¶”ì²œí•´ì¤˜\në‹¨ë³€ ì˜¤ëŠ˜ ì ì‹¬ ë©”ë‰´ë¡œëŠ” ë§¤ì½¤í•œ ë‹­ê°ˆë¹„ë‚˜ ì‹œì›í•œ ëƒ‰ë©´ ì–´ë– ì„¸ìš”? ğŸ˜Š \n\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"question = \"ë„ˆëŠ” ë‚˜ì´ê°€ ëª‡ì‚´ì´ì•¼\"\nprompt = f\"Question: {question}\\nAnswer in a complete sentence:\"\n\nresponse = gemini_model.generate_content(prompt)\nanswer = response.candidates[0].content.parts[0].text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T07:52:40.567860Z","iopub.execute_input":"2024-11-06T07:52:40.568284Z","iopub.status.idle":"2024-11-06T07:52:41.941272Z","shell.execute_reply.started":"2024-11-06T07:52:40.568243Z","shell.execute_reply":"2024-11-06T07:52:41.940037Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}