{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install -q langchain langchain-community langchain_huggingface chromadb wikipedia","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T05:01:50.743987Z","iopub.execute_input":"2024-11-05T05:01:50.744393Z","iopub.status.idle":"2024-11-05T05:02:44.814494Z","shell.execute_reply.started":"2024-11-05T05:01:50.744351Z","shell.execute_reply":"2024-11-05T05:02:44.813091Z"}},"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.1 which is incompatible.\njupyterlab 4.2.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.5.0 requires kubernetes<27,>=8.0.0, but you have kubernetes 31.0.0 which is incompatible.\nkfp 2.5.0 requires requests-toolbelt<1,>=0.8.0, but you have requests-toolbelt 1.0.0 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nthinc 8.3.2 requires numpy<2.1.0,>=2.0.0; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\nydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nfrom langchain_community.document_loaders import WikipediaLoader\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\nfrom langchain_community.vectorstores import Chroma\nfrom langchain.chains import RetrievalQA\nfrom langchain.prompts import PromptTemplate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T05:07:01.604163Z","iopub.execute_input":"2024-11-05T05:07:01.604684Z","iopub.status.idle":"2024-11-05T05:07:01.610730Z","shell.execute_reply.started":"2024-11-05T05:07:01.604644Z","shell.execute_reply":"2024-11-05T05:07:01.609560Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T05:07:02.155813Z","iopub.execute_input":"2024-11-05T05:07:02.156947Z","iopub.status.idle":"2024-11-05T05:07:02.162416Z","shell.execute_reply.started":"2024-11-05T05:07:02.156851Z","shell.execute_reply":"2024-11-05T05:07:02.161244Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"os.environ.get(\"HUGGINGFACEHUB_API_TOKEN\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T05:07:02.850741Z","iopub.execute_input":"2024-11-05T05:07:02.851974Z","iopub.status.idle":"2024-11-05T05:07:02.859325Z","shell.execute_reply.started":"2024-11-05T05:07:02.851927Z","shell.execute_reply":"2024-11-05T05:07:02.858327Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"'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'"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"from langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.llms import HuggingFaceHub\n\n# set Korean embedding and llm odel\nhf_embeddings = HuggingFaceEmbeddings(model_name=\"jhgan/ko-sroberta-multitask\")\n\nhf_llm = HuggingFaceHub(\n    repo_id=\"skt/kogpt2-base-v2\",\n    model_kwargs={\"task\": \"text-generation\"}\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T05:07:03.379371Z","iopub.execute_input":"2024-11-05T05:07:03.380654Z","iopub.status.idle":"2024-11-05T05:07:38.646363Z","shell.execute_reply.started":"2024-11-05T05:07:03.380605Z","shell.execute_reply":"2024-11-05T05:07:38.645151Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/3726747796.py:5: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n  hf_embeddings = HuggingFaceEmbeddings(model_name=\"jhgan/ko-sroberta-multitask\")\n/opt/conda/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n  from tqdm.autonotebook import tqdm, trange\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a45cf978c70c4b4e9d4702762548568e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/123 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc529149a28a4aca94d04d1d5b047c8c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/4.86k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"238fea9079ef4d37b34b3eb3a47a8178"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e37e0180bfd490d98e5c0199a548e47"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/744 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"165419e9f5874b3b9b6e7bd6d7afd139"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/443M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2ac057b40604885a00231a73244cfdf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/585 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb8fc76fcf00497ba604dba41d45f099"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"199918771d7a4a2bb0357f4142430361"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/495k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0e7bd8caef740f4bd9218692acce6d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/156 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"131cd9a1dd18429ca37655dd87f644e2"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c05c285431ad421ebc63569f5d401044"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_30/3726747796.py:7: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEndpoint``.\n  hf_llm = HuggingFaceHub(\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import requests\nfrom langchain.schema import Document\nfrom bs4 import BeautifulSoup\n\n# By default, English documents (https://en.wikipedia.org))\n# def load_Wiki_docs(\"흑백요리사\"):\n#     loader = WikipediaLoader(query=query, load_max_docs=1)\n#     documents = loader.load()\n    \n#     text_splitter = RecursiveCharacterTextSplitter(\n#         chunk_size=1000,\n#         chunk_overlap=200\n#     )\n#     splits = text_splitter.split_documents(documents)\n    \n#     return splits\n\n\n# For Korean query, get results from Korean wikipedia website and crawl and parse results\ndef load_Korean_wiki_docs(topic):\n\n    url = f\"https://ko.wikipedia.org/wiki/{topic}\"\n    \n    response = requests.get(url)\n    response.raise_for_status()  # raise Exception when error occurs\n\n    # HTML parsing and extract body contents\n    soup = BeautifulSoup(response.text, 'html.parser')\n    content = soup.find('div', {'class': 'mw-parser-output'})  # find div including body contents \n    \n    # Extract contents\n    paragraphs = content.find_all('p')\n    text = \"\\n\".join([p.get_text() for p in paragraphs])  # concat all context in <p> tags \n \n    # convert to Document object (required for LangChain)\n    documents = [Document(page_content=text, metadata={\"source\": url})]\n    \n    text_splitter = RecursiveCharacterTextSplitter(\n        chunk_size=1000,\n        chunk_overlap=200\n    )\n    splits = text_splitter.split_documents(documents)\n    \n    return splits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T05:07:38.648423Z","iopub.execute_input":"2024-11-05T05:07:38.649168Z","iopub.status.idle":"2024-11-05T05:07:38.875793Z","shell.execute_reply.started":"2024-11-05T05:07:38.649129Z","shell.execute_reply":"2024-11-05T05:07:38.874677Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def create_vectorstore(splits): \n    vectorstore = Chroma.from_documents(documents=splits, embedding=hf_embeddings)\n    return vectorstore","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T05:07:38.877127Z","iopub.execute_input":"2024-11-05T05:07:38.877954Z","iopub.status.idle":"2024-11-05T05:07:38.883997Z","shell.execute_reply.started":"2024-11-05T05:07:38.877912Z","shell.execute_reply":"2024-11-05T05:07:38.882961Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"topic = \"흑백요리사\"\n# Load wikipedia documents for this topic\nsplits = load_Korean_wiki_docs(topic)\n# Create vectorstore with this fetched docs\nvectorstore = create_vectorstore(splits)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T05:07:38.886501Z","iopub.execute_input":"2024-11-05T05:07:38.886856Z","iopub.status.idle":"2024-11-05T05:07:41.547227Z","shell.execute_reply.started":"2024-11-05T05:07:38.886818Z","shell.execute_reply":"2024-11-05T05:07:41.545950Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"splits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T05:07:41.549146Z","iopub.execute_input":"2024-11-05T05:07:41.549513Z","iopub.status.idle":"2024-11-05T05:07:41.556482Z","shell.execute_reply.started":"2024-11-05T05:07:41.549473Z","shell.execute_reply":"2024-11-05T05:07:41.555160Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"[Document(metadata={'source': 'https://ko.wikipedia.org/wiki/흑백요리사'}, page_content='《흑백요리사: 요리 계급 전쟁》(영어: Culinary Class Wars)은 넷플릭스의 요리 서바이벌 프로그램이다. 방송 직후 세계 여러 나라에서 시청률 1위를 기록했고, 대만인들의 한국 관광 열풍과 한국 음식에 대한 사랑을 불러일으켰다. 유명 레스토랑 셰프 등 100인의 요리사가 출연한다. 심사위원은 백종원과 안성재가 맡았다. 가제는 《호날두요리사》였다.[1]')]"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"# 1. Use langchain RAG","metadata":{}},{"cell_type":"code","source":"def create_rag_chain(vectorstore):\n    prompt_template = \"\"\"문맥을 참고하여 질문에 정확하고 간결하게 답하십시오.\n    문맥: {context}\n    질문: {question}\n    답변:\"\"\"\n    PROMPT = PromptTemplate(\n        template=prompt_template, input_variables=[\"context\", \"question\"]\n    )\n\n    chain_type_kwargs = {\"prompt\": PROMPT}\n\n    # Make context shorter\n    # def short_context(context, max_length=300):\n    #     return context[:max_length] if len(context) > max_length else context\n    \n    # class ShortContextRetriever(BaseRetriever):\n    #     def __init__(self, retriever):\n    #         super().__init__()\n    #         self._retriever = retriever\n        \n    #     def get_relevant_documents(self, query):\n    #         docs = self._retriever.get_relevant_documents(query)\n    #         for doc in docs:\n    #             doc.page_content = short_context(doc.page_content)\n    #         return docs\n    \n    # retriever = ShortContextRetriever(vectorstore.as_retriever())\n    \n    qa_chain = RetrievalQA.from_chain_type(\n        llm=hf_llm,\n        chain_type=\"stuff\",\n        retriever=vectorstore.as_retriever(),\n        chain_type_kwargs=chain_type_kwargs,\n        return_source_documents=True\n    )\n    \n    return qa_chain","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T05:07:41.558391Z","iopub.execute_input":"2024-11-05T05:07:41.559479Z","iopub.status.idle":"2024-11-05T05:07:43.271566Z","shell.execute_reply.started":"2024-11-05T05:07:41.559430Z","shell.execute_reply":"2024-11-05T05:07:43.270339Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# create langchang RAG chain\nqa_chain = create_rag_chain(vectorstore)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T05:07:43.273244Z","iopub.execute_input":"2024-11-05T05:07:43.273706Z","iopub.status.idle":"2024-11-05T05:07:43.290052Z","shell.execute_reply.started":"2024-11-05T05:07:43.273653Z","shell.execute_reply":"2024-11-05T05:07:43.288920Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"question = \"심사위원을 누가 맡았어?\"\n\n# result = qa_chain({\"query\": question})\nresult = qa_chain.invoke({\"query\": question})\n\nprint (\"결과:\")\nprint(result[\"result\"])\n\nprint(\"출처:\")\nfor doc in result[\"source_documents\"]:\n    print(doc.page_content)\n    print(\"---\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T05:07:43.291659Z","iopub.execute_input":"2024-11-05T05:07:43.292226Z","iopub.status.idle":"2024-11-05T05:07:44.000762Z","shell.execute_reply.started":"2024-11-05T05:07:43.292168Z","shell.execute_reply":"2024-11-05T05:07:43.999491Z"}},"outputs":[{"name":"stdout","text":"결과:\n문맥을 참고하여 질문에 정확하고 간결하게 답하십시오.\n    문맥: 《흑백요리사: 요리 계급 전쟁》(영어: Culinary Class Wars)은 넷플릭스의 요리 서바이벌 프로그램이다. 방송 직후 세계 여러 나라에서 시청률 1위를 기록했고, 대만인들의 한국 관광 열풍과 한국 음식에 대한 사랑을 불러일으켰다. 유명 레스토랑 셰프 등 100인의 요리사가 출연한다. 심사위원은 백종원과 안성재가 맡았다. 가제는 《호날두요리사》였다.[1]\n    질문: 심사위원을 누가 맡았어?\n    답변: 쉐프들이 심사위원으로 참여했어?\n( 쉐프들이 심사위원으로 참여했어?)\n심사위원: 쉐프들이 심사위원으로 참여했어?\n( 쉐프들이 심사위원으로 참여했어?)\n심사위원: 쉐프들이 심사위원으로 참여했어?\n( 쉐프들이 심사위원으로 참여했어?)\n심사위원: 쉐프들이 심사위원으로 참여했어?\n( 쉐프들이 심사위원으로 참여했어?)\n심사위원:\n출처:\n《흑백요리사: 요리 계급 전쟁》(영어: Culinary Class Wars)은 넷플릭스의 요리 서바이벌 프로그램이다. 방송 직후 세계 여러 나라에서 시청률 1위를 기록했고, 대만인들의 한국 관광 열풍과 한국 음식에 대한 사랑을 불러일으켰다. 유명 레스토랑 셰프 등 100인의 요리사가 출연한다. 심사위원은 백종원과 안성재가 맡았다. 가제는 《호날두요리사》였다.[1]\n---\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"docs = vectorstore.as_retriever().get_relevant_documents(question)\ndocs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T05:13:01.862383Z","iopub.execute_input":"2024-11-05T05:13:01.863336Z","iopub.status.idle":"2024-11-05T05:13:01.949079Z","shell.execute_reply.started":"2024-11-05T05:13:01.863291Z","shell.execute_reply":"2024-11-05T05:13:01.947966Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"[Document(metadata={'source': 'https://ko.wikipedia.org/wiki/흑백요리사'}, page_content='《흑백요리사: 요리 계급 전쟁》(영어: Culinary Class Wars)은 넷플릭스의 요리 서바이벌 프로그램이다. 방송 직후 세계 여러 나라에서 시청률 1위를 기록했고, 대만인들의 한국 관광 열풍과 한국 음식에 대한 사랑을 불러일으켰다. 유명 레스토랑 셰프 등 100인의 요리사가 출연한다. 심사위원은 백종원과 안성재가 맡았다. 가제는 《호날두요리사》였다.[1]')]"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"docs = vectorstore.similarity_search(question, k=4)\ndocs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T05:12:58.940356Z","iopub.execute_input":"2024-11-05T05:12:58.940840Z","iopub.status.idle":"2024-11-05T05:12:59.031184Z","shell.execute_reply.started":"2024-11-05T05:12:58.940794Z","shell.execute_reply":"2024-11-05T05:12:59.030226Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"[Document(metadata={'source': 'https://ko.wikipedia.org/wiki/흑백요리사'}, page_content='《흑백요리사: 요리 계급 전쟁》(영어: Culinary Class Wars)은 넷플릭스의 요리 서바이벌 프로그램이다. 방송 직후 세계 여러 나라에서 시청률 1위를 기록했고, 대만인들의 한국 관광 열풍과 한국 음식에 대한 사랑을 불러일으켰다. 유명 레스토랑 셰프 등 100인의 요리사가 출연한다. 심사위원은 백종원과 안성재가 맡았다. 가제는 《호날두요리사》였다.[1]')]"},"metadata":{}}],"execution_count":19},{"cell_type":"markdown","source":"# 2. Use QA pipeline with vectorstor similarity search","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n\n# Load model and tokenizer\nmodel_name = \"yjgwak/klue-bert-base-finetuned-squard-kor-v1\"\nmodel = AutoModelForQuestionAnswering.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\n# Set Q_A pipeline\nqa_pipeline = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T05:07:44.143393Z","iopub.execute_input":"2024-11-05T05:07:44.143820Z","iopub.status.idle":"2024-11-05T05:07:51.256139Z","shell.execute_reply.started":"2024-11-05T05:07:44.143777Z","shell.execute_reply":"2024-11-05T05:07:51.255178Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/635 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c7a7372c17242cca806b6e2e6cc3745"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f62a9920569a49b28cd642a3d10255e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/367 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec9a72a133764f6faf4d7ca7249cb0e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/246k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4ff9f42e7694766a195c8d86e59d38e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e097f7df36ce4646aefcb3baa1902cd1"}},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"# Example: define question and context \nquestion = \"오늘 날씨 어때?\"\ncontext = \"오늘의 날씨는 맑고 따뜻한 기온이 유지될 것으로 보입니다.\"\n\n# model chain\nresult = qa_pipeline(question=question, context=context)\n\n# Result\nprint(\"질문:\", question)\nprint(\"답변:\", result['answer'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T05:07:51.257434Z","iopub.execute_input":"2024-11-05T05:07:51.257809Z","iopub.status.idle":"2024-11-05T05:07:51.364032Z","shell.execute_reply.started":"2024-11-05T05:07:51.257768Z","shell.execute_reply":"2024-11-05T05:07:51.362837Z"}},"outputs":[{"name":"stdout","text":"질문: 오늘 날씨 어때?\n답변: 맑고 따뜻한 기온이\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# search context in VectorStore\ndef retrieve_context(question, vectorstore):\n    docs = vectorstore.similarity_search(question, k=1)\n    if docs:\n        return docs[0].page_content  # return first relevant doc\n    else:\n        return None\n\n# Generate answer based on query and searched context similar to RAG chain\ndef answer_question_with_context(question, vectorstore):\n    context = retrieve_context(question, vectorstore)\n    if context:\n        result = qa_pipeline(question=question, context=context)\n        return result['answer'], context  # return answer and used source doc\n    else:\n        return \"관련 문맥을 찾지 못했습니다.\", None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T05:07:51.365671Z","iopub.execute_input":"2024-11-05T05:07:51.366250Z","iopub.status.idle":"2024-11-05T05:07:51.374312Z","shell.execute_reply.started":"2024-11-05T05:07:51.366194Z","shell.execute_reply":"2024-11-05T05:07:51.373229Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Example\nquestion = \"심사위원을 누가 맡았어?\"\n\nanswer, used_context = answer_question_with_context(question, vectorstore)\n\nprint(\"질문:\", question)\nprint(\"답변:\", answer)\nprint(\"사용된 문맥:\", used_context)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T05:07:51.375703Z","iopub.execute_input":"2024-11-05T05:07:51.376078Z","iopub.status.idle":"2024-11-05T05:07:51.683413Z","shell.execute_reply.started":"2024-11-05T05:07:51.376031Z","shell.execute_reply":"2024-11-05T05:07:51.682267Z"}},"outputs":[{"name":"stdout","text":"질문: 심사위원을 누가 맡았어?\n답변: 백종원과 안성재가\n사용된 문맥: 《흑백요리사: 요리 계급 전쟁》(영어: Culinary Class Wars)은 넷플릭스의 요리 서바이벌 프로그램이다. 방송 직후 세계 여러 나라에서 시청률 1위를 기록했고, 대만인들의 한국 관광 열풍과 한국 음식에 대한 사랑을 불러일으켰다. 유명 레스토랑 셰프 등 100인의 요리사가 출연한다. 심사위원은 백종원과 안성재가 맡았다. 가제는 《호날두요리사》였다.[1]\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}